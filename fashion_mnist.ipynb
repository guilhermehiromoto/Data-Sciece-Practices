{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-28T19:02:55.805306Z","iopub.execute_input":"2021-10-28T19:02:55.806127Z","iopub.status.idle":"2021-10-28T19:02:55.836371Z","shell.execute_reply.started":"2021-10-28T19:02:55.805968Z","shell.execute_reply":"2021-10-28T19:02:55.835045Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df_train= pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:02:58.572682Z","iopub.execute_input":"2021-10-28T19:02:58.573358Z","iopub.status.idle":"2021-10-28T19:03:04.987939Z","shell.execute_reply.started":"2021-10-28T19:02:58.573302Z","shell.execute_reply":"2021-10-28T19:03:04.986748Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:06.521269Z","iopub.execute_input":"2021-10-28T19:03:06.521920Z","iopub.status.idle":"2021-10-28T19:03:06.527231Z","shell.execute_reply.started":"2021-10-28T19:03:06.521866Z","shell.execute_reply":"2021-10-28T19:03:06.526173Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:08.333879Z","iopub.execute_input":"2021-10-28T19:03:08.334249Z","iopub.status.idle":"2021-10-28T19:03:09.403312Z","shell.execute_reply.started":"2021-10-28T19:03:08.334217Z","shell.execute_reply":"2021-10-28T19:03:09.402453Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"labels = torch.Tensor(df_train['label'].values)\n\nlabels","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:11.896996Z","iopub.execute_input":"2021-10-28T19:03:11.897432Z","iopub.status.idle":"2021-10-28T19:03:11.968446Z","shell.execute_reply.started":"2021-10-28T19:03:11.897395Z","shell.execute_reply":"2021-10-28T19:03:11.967127Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"classes = {\n    0:'T-shirt/top',\n    1:'Trouser',\n    2:'Pullover',\n    3:'Dress',\n    4:'Coat',\n    5:'Sandal',\n    6:'Shirt',\n    7:'Sneaker',\n    8:'Bag',\n    9:'Ankle boot',\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:13.662208Z","iopub.execute_input":"2021-10-28T19:03:13.662633Z","iopub.status.idle":"2021-10-28T19:03:13.667726Z","shell.execute_reply.started":"2021-10-28T19:03:13.662597Z","shell.execute_reply":"2021-10-28T19:03:13.666775Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"features = torch.Tensor(df_train.iloc[:,1:].values)\nplt.title(classes[labels[150].item()])\nplt.imshow(features[150].reshape(28,28))\nfeatures","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:15.581576Z","iopub.execute_input":"2021-10-28T19:03:15.582274Z","iopub.status.idle":"2021-10-28T19:03:15.921991Z","shell.execute_reply.started":"2021-10-28T19:03:15.582224Z","shell.execute_reply":"2021-10-28T19:03:15.920434Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#normalizing the pixel values to 0-1 range\nmax_value = torch.max(features)\nfeatures = features/max_value","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:17.909581Z","iopub.execute_input":"2021-10-28T19:03:17.910036Z","iopub.status.idle":"2021-10-28T19:03:18.441001Z","shell.execute_reply.started":"2021-10-28T19:03:17.909998Z","shell.execute_reply":"2021-10-28T19:03:18.439685Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#to solve this task i will use just a simple soft max layer\nfrom torch import nn\nnet = nn.Sequential(nn.Linear(784,256),nn.ReLU(),\n                    nn.Linear(256,256),nn.ReLU(),\n                    nn.Linear(256,10))\nnet","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:20.217464Z","iopub.execute_input":"2021-10-28T19:03:20.217942Z","iopub.status.idle":"2021-10-28T19:03:20.233351Z","shell.execute_reply.started":"2021-10-28T19:03:20.217898Z","shell.execute_reply":"2021-10-28T19:03:20.232067Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def init_weight(m):\n    if type(m) == nn.Linear:\n        nn.init.normal_(m.weight,std=0.01)\n        \nnet.apply(init_weight)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:22.180123Z","iopub.execute_input":"2021-10-28T19:03:22.180511Z","iopub.status.idle":"2021-10-28T19:03:22.191260Z","shell.execute_reply.started":"2021-10-28T19:03:22.180476Z","shell.execute_reply":"2021-10-28T19:03:22.190484Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"loss = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:27.913035Z","iopub.execute_input":"2021-10-28T19:03:27.913824Z","iopub.status.idle":"2021-10-28T19:03:27.918580Z","shell.execute_reply.started":"2021-10-28T19:03:27.913776Z","shell.execute_reply":"2021-10-28T19:03:27.917455Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"trainer = torch.optim.SGD(net.parameters(), lr=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:30.709558Z","iopub.execute_input":"2021-10-28T19:03:30.710269Z","iopub.status.idle":"2021-10-28T19:03:30.716426Z","shell.execute_reply.started":"2021-10-28T19:03:30.710219Z","shell.execute_reply":"2021-10-28T19:03:30.715136Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#lets construct a iterator with the mini batch\ndef load_array(data_arrays, batch_size):\n    dataset = torch.utils.data.TensorDataset(*data_arrays)\n    return torch.utils.data.DataLoader(dataset,batch_size)\n\nbatch_size = 256\ndata_iter = load_array((features,labels),batch_size)\nnext(iter(data_iter))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:32.523928Z","iopub.execute_input":"2021-10-28T19:03:32.524513Z","iopub.status.idle":"2021-10-28T19:03:32.547032Z","shell.execute_reply.started":"2021-10-28T19:03:32.524472Z","shell.execute_reply":"2021-10-28T19:03:32.545905Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"num_epochs = 1000\n\nfor i in range(num_epochs):\n    for X,y in data_iter:\n        l = loss(net(X) ,y.long())\n        trainer.zero_grad()\n        l.backward()\n        trainer.step()\n    l = loss(net(features), labels.long())\n    print(f'epoch {i + 1}, loss {l:f}')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T19:03:34.672324Z","iopub.execute_input":"2021-10-28T19:03:34.672714Z","iopub.status.idle":"2021-10-28T19:03:48.547861Z","shell.execute_reply.started":"2021-10-28T19:03:34.672679Z","shell.execute_reply":"2021-10-28T19:03:48.545922Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"torch.argmax(net(features)[0]).item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nfor i in range(10):\n    index = np.random.randint(60000)\n    plt.subplot(2,5,i+1)\n    plt.title(classes[labels[index].long().item()]+'\\n'+classes[torch.argmax(net(features)[index]).item()])\n    plt.imshow(features[index].reshape(28,28))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_hits = 0\npredicts = net(features)\nfor i in range(60000):\n    if(torch.argmax(predicts[i]).item() == labels[i].long().item()):\n        num_hits+=1\nprint(f'train accuracy:{num_hits*100/60000:f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = torch.Tensor(df_test['label'].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = torch.Tensor(df_test.iloc[:,1:].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(df_test.iloc[:,1:].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#normalizing the pixel values to 0-1 range\nmax_value = torch.max(features)\nfeatures = features/max_value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 256\ndata_iter = load_array((features,labels),batch_size)\nnext(iter(data_iter))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_hits = 0\npredicts = net(features)\nfor i in range(10000):\n    if(torch.argmax(predicts[i]).item() == labels[i].long().item()):\n        num_hits+=1\nprint(f'test accuracy:{num_hits*100/10000:f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nfor i in range(10):\n    index = np.random.randint(10000)\n    plt.subplot(2,5,i+1)\n    plt.title(classes[labels[index].long().item()]+'\\n'+classes[torch.argmax(net(features)[index]).item()])\n    plt.imshow(features[index].reshape(28,28))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imageio as img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = img.imread('../input/real-image/image(1).jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_im = 255- torch.Tensor(im[:,:,0])\nreal_im = real_im/255\nprint(classes[torch.argmax(net(real_im.reshape(784))).item()])\nplt.imshow(real_im)\n#real_im","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = img.imread('../input/alooooo/image(2).jpg')\nreal_im = 255- torch.Tensor(im[:,:,0])\nreal_im = real_im/255\nprint(classes[torch.argmax(net(real_im.reshape(784))).item()])\nplt.imshow(real_im)\n#real_im","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}